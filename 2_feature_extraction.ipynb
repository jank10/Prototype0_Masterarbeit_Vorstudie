{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction of People\n",
    "\n",
    "This notebook extracts skills and project involvement from a knowledge graph and saves them as new nodes and relationships. Moreover, the code creates a vector index within neo4j.\n",
    "\n",
    "You need a .env file which is configured with your neo4j credentials (see knowledge_graph_construction.ipynb) and your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "#from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Neo4jVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Configure OpenAI API and neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j configuration & constraints\n",
    "neo4j_uri = os.getenv(\"NEO4J_URI\")\n",
    "neo4j_user = os.getenv(\"NEO4J_USERNAME\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Function to fetch all employee IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch all employee IDs\n",
    "def fetch_all_employees(session):\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Person)\n",
    "    RETURN p.id AS employee_id\n",
    "    \"\"\"\n",
    "    result = session.run(query)\n",
    "    return [record['employee_id'] for record in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Function to fetch employee data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch employee data\n",
    "def fetch_employee_data(employee_id, session):\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Person {id: $employee_id})\n",
    "    OPTIONAL MATCH (p)-[:BELONGS_TO]->(t:Team),\n",
    "                   (p)-[:REPORTS_TO]->(manager:Person),\n",
    "                   (p)-[:WROTE]->(chat:chat_message),\n",
    "                   (p)-[:RECEIVED]->(recchat:chat_message),\n",
    "                   (p)-[:WROTE]->(email:email_message),\n",
    "                   (p)-[:RECEIVED]->(recemail:email_message),\n",
    "                   (p)-[:CREATED]->(doc:Document)\n",
    "    WITH p, \n",
    "         collect(DISTINCT t) AS teams,\n",
    "         collect(DISTINCT manager) AS managers,\n",
    "         collect(DISTINCT chat) AS sentchatMessages,\n",
    "         collect(DISTINCT recchat) AS receivedchatMessages,\n",
    "         collect(DISTINCT email) AS sentemailMessages,\n",
    "         collect(DISTINCT recemail) AS receivedemailMessages,\n",
    "         collect(DISTINCT doc) AS documents\n",
    "    RETURN p, teams, managers, sentchatMessages, receivedchatMessages, sentemailMessages, receivedemailMessages, documents\n",
    "    \"\"\"\n",
    "    result = session.run(query, employee_id=employee_id)\n",
    "    data = [record.data() for record in result]\n",
    "    return json.dumps(data)  # Convert data to JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #only relevant for single test run\n",
    "# # Fetch data for a specific employee (example ID)\n",
    "# employee_data_json = fetch_employee_data(22)\n",
    "# print(employee_data_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Extract skills and project involvment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to call the OpenAI API\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",                \n",
    "    temperature=0,                \n",
    "    max_tokens=1500,                \n",
    ")\n",
    "\n",
    "def extract_skills_and_projects(employee_data_json):\n",
    "    data = json.loads(employee_data_json)\n",
    "    if not data:\n",
    "        return [], []  # Handle empty data\n",
    "    employee_data = data[0]  # Assuming single employee data\n",
    "    prompt_template = \"\"\"\n",
    "    Extract the key skills and projects for the following employee data:\n",
    "    Name: {name}\n",
    "    Role: {role}\n",
    "    Team: {team}\n",
    "    Manager: {manager}\n",
    "    Sent Chat Messages: {sent_chat}\n",
    "    Received Chat Messages: {received_chat}\n",
    "    Sent Email Messages: {sent_email}\n",
    "    Received Email Messages: {received_email}\n",
    "    Documents Created: {documents}\n",
    "\n",
    "    Provide a list of skills and projects in a structured format as follows:\n",
    "    Skills: skill1, skill2, ...\n",
    "    Projects: project1, project2, ...\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare prompt data\n",
    "    name = employee_data['p']['name']\n",
    "    role = employee_data['p']['role']\n",
    "    team = employee_data['teams'][0]['name'] if employee_data['teams'] else \"N/A\"\n",
    "    manager = employee_data['managers'][0]['name'] if employee_data['managers'] else \"N/A\"\n",
    "    sent_chat = \", \".join([msg['content'] for msg in employee_data['sentchatMessages']])\n",
    "    received_chat = \", \".join([msg['content'] for msg in employee_data['receivedchatMessages']])\n",
    "    sent_email = \", \".join([msg['subject_line'] for msg in employee_data['sentemailMessages']])\n",
    "    received_email = \", \".join([msg['subject_line'] for msg in employee_data['receivedemailMessages']])\n",
    "    documents = \", \".join([doc['document_name'] for doc in employee_data['documents']])\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = prompt_template.format(\n",
    "        name=name, role=role, team=team, manager=manager,\n",
    "        sent_chat=sent_chat, received_chat=received_chat,\n",
    "        sent_email=sent_email, received_email=received_email,\n",
    "        documents=documents\n",
    "    )\n",
    "\n",
    "    # Generate the skills and projects using the LLM\n",
    "    response = llm(prompt)\n",
    "    # Parse the response\n",
    "    content = response.content\n",
    "    skills = []\n",
    "    projects = []\n",
    "    try:\n",
    "        lines = content.split('\\n')\n",
    "        for line in lines:\n",
    "            if line.startswith(\"Skills:\"):\n",
    "                skills = [skill.strip() for skill in line.replace(\"Skills:\", \"\").strip().split(',')]\n",
    "            elif line.startswith(\"Projects:\"):\n",
    "                projects = [project.strip() for project in line.replace(\"Projects:\", \"\").strip().split(',')]\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing response: {e}\")\n",
    "\n",
    "    return skills, projects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Safe skills and projects as nodes/relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_skills_and_projects(employee_id, skills, projects, session):\n",
    "    for skill in skills:\n",
    "        query = \"\"\"\n",
    "        MATCH (p:Person {id: $employee_id})\n",
    "        MERGE (s:Skill {name: $skill})\n",
    "        MERGE (p)-[:HAS_SKILL]->(s)\n",
    "        \"\"\"\n",
    "        session.run(query, employee_id=employee_id, skill=skill)\n",
    "\n",
    "    for project in projects:\n",
    "        query = \"\"\"\n",
    "        MATCH (p:Person {id: $employee_id})\n",
    "        MERGE (pr:Project {name: $project})\n",
    "        MERGE (p)-[:WORKS_ON]->(pr)\n",
    "        \"\"\"\n",
    "        session.run(query, employee_id=employee_id, project=project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/pkg41pm57tjgqckrqnnwf_080000gn/T/ipykernel_5896/2500548549.py:50: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed employee ID: 1\n",
      "Processed employee ID: 2\n",
      "Processed employee ID: 4\n",
      "Processed employee ID: 5\n",
      "Processed employee ID: 6\n",
      "Processed employee ID: 7\n",
      "Processed employee ID: 8\n",
      "Processed employee ID: 10\n",
      "Processed employee ID: 12\n",
      "Processed employee ID: 13\n",
      "Processed employee ID: 15\n",
      "Processed employee ID: 16\n",
      "Processed employee ID: 17\n",
      "Processed employee ID: 18\n",
      "Processed employee ID: 19\n",
      "Processed employee ID: 20\n",
      "Processed employee ID: 21\n",
      "Processed employee ID: 22\n",
      "Processed employee ID: 23\n",
      "Processed employee ID: 24\n",
      "Processed employee ID: 25\n",
      "Processed employee ID: 28\n",
      "Processed employee ID: 29\n",
      "Processed employee ID: 30\n",
      "Processed employee ID: 31\n"
     ]
    }
   ],
   "source": [
    "# Main execution loop\n",
    "\n",
    "with driver.session() as session:\n",
    "        #employee_ids = [2] #for testing single IDs\n",
    "        employee_ids = fetch_all_employees(session) #for entire KG\n",
    "        for employee_id in employee_ids:\n",
    "            employee_data_json = fetch_employee_data(employee_id, session)\n",
    "            skills, projects = extract_skills_and_projects(employee_data_json)\n",
    "            if skills or projects:\n",
    "                save_skills_and_projects(employee_id, skills, projects, session)\n",
    "                print(f\"Processed employee ID: {employee_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Create Vector Index (Hybrid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings_model,\n",
    "    search_type=\"hybrid\",  \n",
    "    node_label=\"Skill\",\n",
    "    text_node_properties=[\"name\"],\n",
    "    embedding_node_property=\"embedding\",\n",
    "    index_name = \"skill_index_vector\",\n",
    "    keyword_index_name = \"skill_index_fulltext\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index_projects = Neo4jVector.from_existing_graph(\n",
    "    embeddings_model,\n",
    "    search_type=\"hybrid\",  # Hybrid search allows combining vector and exact queries\n",
    "    node_label=\"Project\",\n",
    "    text_node_properties=[\"name\"],\n",
    "    embedding_node_property=\"embedding\",\n",
    "    index_name = \"project_index_vector\",\n",
    "    keyword_index_name = \"project_index_fulltext\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaistack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
