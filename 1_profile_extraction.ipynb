{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile Summary Creation\n",
    "\n",
    "This notebook extracts information about person from knowledge graph, creates a summary about that person and saves it as a property of the person node.\n",
    "\n",
    "You need a .env file which is configured with your neo4j credentials (see 0_knowledge_graph_construction.ipynb) and your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Configure OpenAI API and neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_uri = os.getenv(\"NEO4J_URI\")\n",
    "neo4j_user = os.getenv(\"NEO4J_USERNAME\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Function to fetch all employee IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_employees(session):\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Person)\n",
    "    RETURN p.id AS employee_id\n",
    "    \"\"\"\n",
    "    result = session.run(query)\n",
    "    return [record['employee_id'] for record in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Function to fetch employee data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_employee_data(employee_id, session):\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Person {id: $employee_id})\n",
    "    OPTIONAL MATCH (p)-[:BELONGS_TO]->(t:Team),\n",
    "                   (p)-[:REPORTS_TO]->(manager:Person),\n",
    "                   (p)-[:WROTE]->(chat:chat_message),\n",
    "                   (p)-[:RECEIVED]->(recchat:chat_message),\n",
    "                   (p)-[:WROTE]->(email:email_message),\n",
    "                   (p)-[:RECEIVED]->(recemail:email_message),\n",
    "                   (p)-[:CREATED]->(doc:Document)\n",
    "    WITH p, \n",
    "         collect(DISTINCT t) AS teams,\n",
    "         collect(DISTINCT manager) AS managers,\n",
    "         collect(DISTINCT chat) AS sentchatMessages,\n",
    "         collect(DISTINCT recchat) AS receivedchatMessages,\n",
    "         collect(DISTINCT email) AS sentemailMessages,\n",
    "         collect(DISTINCT recemail) AS receivedemailMessages,\n",
    "         collect(DISTINCT doc) AS documents\n",
    "    RETURN p, teams, managers, sentchatMessages, receivedchatMessages, sentemailMessages, receivedemailMessages, documents\n",
    "    \"\"\"\n",
    "    result = session.run(query, employee_id=employee_id)\n",
    "    data = [record.data() for record in result]\n",
    "    return json.dumps(data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create a profile summary from the extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to call the OpenAI API\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",                \n",
    "    temperature=0,                \n",
    "    max_tokens=1500,                \n",
    ")\n",
    "\n",
    "def generate_profile_summary(employee_data_json):\n",
    "    data = json.loads(employee_data_json)\n",
    "    employee_data = data[0]  # Assuming single employee data\n",
    "    prompt_template = \"\"\"\n",
    "    Create a concise profile summary for the following employee data:\n",
    "    Name: {name}\n",
    "    Role: {role}\n",
    "    Team: {team}\n",
    "    Manager: {manager}\n",
    "    Sent Chat Messages: {sent_chat}\n",
    "    Received Chat Messages: {received_chat}\n",
    "    Sent Email Messages: {sent_email}\n",
    "    Received Email Messages: {received_email}\n",
    "    Documents Created: {documents}\n",
    "\n",
    "    Use very precise and straight forward language.\n",
    "    Don't dress up the text, remain factual instead.\n",
    "    Provide a summary highlighting key skills, contributions, and role in the team.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare prompt data\n",
    "    name = employee_data['p']['name']\n",
    "    role = employee_data['p']['role']\n",
    "    team = employee_data['teams'][0]['name'] if employee_data['teams'] else \"N/A\"\n",
    "    manager = employee_data['managers'][0]['name'] if employee_data['managers'] else \"N/A\"\n",
    "    sent_chat = \", \".join([msg['content'] for msg in employee_data['sentchatMessages']])\n",
    "    received_chat = \", \".join([msg['content'] for msg in employee_data['receivedchatMessages']])\n",
    "    sent_email = \", \".join([msg['subject_line'] for msg in employee_data['sentemailMessages']])\n",
    "    received_email = \", \".join([msg['subject_line'] for msg in employee_data['receivedemailMessages']])\n",
    "    documents = \", \".join([doc['document_name'] for doc in employee_data['documents']])\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = prompt_template.format(\n",
    "        name=name, role=role, team=team, manager=manager,\n",
    "        sent_chat=sent_chat, received_chat=received_chat,\n",
    "        sent_email=sent_email, received_email=received_email,\n",
    "        documents=documents\n",
    "    )\n",
    "\n",
    "    # Generate the summary using the LLM\n",
    "    summary = llm(prompt)\n",
    "    return summary.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save summary and embedding\n",
    "def save_profile_summary(employee_id, summary, session):\n",
    "    query = \"\"\"\n",
    "    MATCH (p:Person {id: $employee_id})\n",
    "    SET p.profile_summary = $summary\n",
    "    RETURN p\n",
    "    \"\"\"\n",
    "    result = session.run(query, employee_id=employee_id, summary=summary)\n",
    "    data = [record.data() for record in result]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Main execution loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "        employee_ids = fetch_all_employees(session)\n",
    "        for employee_id in employee_ids:\n",
    "            employee_data_json = fetch_employee_data(employee_id, session)\n",
    "            profile_summary = generate_profile_summary(employee_data_json)\n",
    "            if profile_summary:\n",
    "                save_profile_summary(employee_id, profile_summary, session)\n",
    "                print(f\"Processed employee ID: {employee_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaistack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
